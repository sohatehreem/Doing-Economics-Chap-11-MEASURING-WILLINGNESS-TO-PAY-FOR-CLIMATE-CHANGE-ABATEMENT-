---
title: "MEASURING WILLINGNESS TO PAY FOR CLIMATE CHANGE ABATEMENT"
author: "Soha Tehreem, Mazhar Shahzad,and Muhammad Sohail"
date: today
format:
  html:
    toc: true
    code-fold: true
    code-link: true
editor: visual
execute: 
  freeze: auto
  warning: false
---

## **Learning objectives**

In this project you will:

-   construct indices to measure attitudes or opinions (Part 11.1)

-   use Cronbach's alpha to assess indices for internal consistency (Part 11.1)

-   practise recoding and creating new variables (Part 11.1)

-   compare survey measures of willingness to pay (Part 11.2).

> #### **Key concepts**
>
> -   *Concepts needed for this project*: mean, standard deviation, correlation/correlation coefficient, confidence interval (for difference in means).
>
> -   *Concepts introduced in this project*: Likert scale (frequency scale) and Cronbach's alpha.

## **Introduction**

### **CORE PROJECTS**

This empirical project is related to material in:

-   [Unit 11](https://tinyco.re/8339311) of *Economy, Society, and Public Policy*

-   [Unit 12](https://tinyco.re/5507363) and [Unit 20](https://tinyco.re/1125415) of *The Economy*.

When designing policies to reduce carbon emissions or air pollution, or to save an endangered species or preserve biodiversity, economists face the problem that markets for environmental amenities are missing. How can the value to people of the abatement of environmental damage be calculated and set against the cost of implementing any abatement?

As explained in [*The Economy*](https://tinyco.re/7509119), a number of methods can be used to estimate the value of abatement. One method, called **contingent valuation**⁠, involves asking people directly---for example, through a survey---how much they value the good.

Two common ways of obtaining information about willingness to pay (WTP) are:

-   *dichotomous choice (DC)*: presenting individuals with an amount, to which they respond with either 'yes/willing to pay' or 'no/not willing to pay' (sometimes a 'no response' option is also offered)

-   *a two-way payment ladder (TWPL)*: asking individuals to state the minimum and maximum amount they are willing to pay (selecting from a pre-specified list of amounts).

As with all subjective measures, both of these methods face different kinds of response biases. In this project, we ask whether they give the same results on average.

The issue of how to measure WTP for non-market goods, such as abatement of pollution, is important for policymaking. Incorrectly estimating the WTP may result in too much or too little abatement.

For estimates of the cost of abatement of greenhouse gases, see *The Economy* Figures 20.9 and 20.26 in [Sections 20.3](https://tinyco.re/6032279) and [20.10](https://tinyco.re/8336661) respectively.

We will look at climate change mitigation as an example. Since tackling climate change may entail short-term costs such as reforestation of degraded forests, governments may want to know how much their citizens are willing to pay to reduce carbon emissions as a method of mitigating climate change.

The German government sponsored a nationwide online survey that investigated the effect of question format (DC or TWPL) on WTP responses. A representative sample of participants aged 18--69 were randomly assigned to either question format, and were asked their willingness to pay for a 10 percentage point increase in Germany's carbon emissions reduction target (from 30% to 40%) by 2020 (compared to 1990). This scenario closely corresponds to Germany's current climate change mitigation strategy.

In this survey, the list of WTP amounts for both question formats ranged from very low values (48 euros per household per year) to very high values (1,440 euros per household per year). We will be using this survey data to compare WTP (mean and median) under each method and assess whether WTP responses differ according to question formats.

## [**Getting started in R**](https://www.core-econ.org/doing-economics/book/text/11-03.html#getting-started-in-r)

For this project you will need the following packages:

-   `tidyverse`, to help with data manipulation

-   `readxl`, to import an Excel spreadsheet

-   `knitr`, to format tables

-   `psych`, to compute Cronbach's alpha.

If you need to install any of these packages, run the following code:

```{r}
#install.packages(c("tidyverse", "readxl", "knitr", "psych"))
```

You can import the libraries now, or when they are used in the R walk-throughs below.

```{r}
library(tidyverse)
library(readxl)
library(knitr)
library(psych)
library(gt)
```

You can add options to executable code like this

### [**Part 11.1 Summarizing the data**](https://www.core-econ.org/doing-economics/book/text/11-03.html#part-111-summarizing-the-data)

> ### **Learning objectives for this part**
>
> -   construct indices to measure attitudes or opinions
>
> -   use Cronbach's alpha to assess indices for internal consistency
>
> -   practise recoding and creating new variables.

We will be using data collected from an internet survey sponsored by the German government.

First, download the survey data and documentation:

-   Download [the data](https://tinyco.re/5330076). Open the file in Excel and read the 'Data dictionary' tab and make sure you know what each variable represents. (Later we will discuss exactly how some of these variables were coded.)

-   The paper ['Data in Brief'](https://tinyco.re/6541656) gives a summary of how the survey was conducted. You may find it helpful to read it before starting on the questions below.

1.  While contingent valuation methods can be useful, they also have shortcomings. Read Section 5 of the paper ['Introduction to economic valuation methods'](https://tinyco.re/3376290) (Pages 16--19), and explain which limitations you think apply particularly to the survey we are looking at. You may also find it useful to look at Table 2 of that paper, which compares stated-preference with revealed-preference methods.

Before comparing between question formats (dichotomous choice (DC) and two-way payment ladder (TWPL)), we will first compare the people assigned to each question format to see if they are similar in demographic characteristics and attitudes towards related topics (such as beliefs about climate change and need for government intervention). If the groups are vastly dissimilar then any observed differences in answers between the groups might be due to differences in attitudes and/or demographics rather than the question format.

Attitudes were assessed using a 1--5 **Likert scaleLikert scale** A numerical scale (usually ranging from 1--5 or 1--7) used to measure attitudes or opinions, with each number representing the individual's level of agreement or disagreement with a particular statement.**close**⁠, where 1 = strongly disagree, and 5 = strongly agree. The way the questions were asked was not consistent, so an answer of 'strongly agree' might mean high climate change skepticism for one question, but low skepticism for another question. In order to combine these questions into an index we need to recode (in this case, reverse-code) some of the variables.

2.  Recode or create the variables as specified:

    \(a\) Reverse-code the following variables (so that 1 is now 5, 2 is now 4, and so on): `cog_2`, `cog_5`, `scepticism_6`, `scepticism_7`.

    \(b\) For the variables `WTP_plmin` and `WTP_plmax`, create new variables with the values replaced as shown in Figure 11.1 (these are the actual amounts, in euros, that individuals selected in the survey, and will be useful for calculating summary measures later).

    | **Original value** | **New value** |
    |:------------------:|:-------------:|
    |         1          |      48       |
    |         2          |      72       |
    |         3          |      84       |
    |         4          |      108      |
    |         5          |      156      |
    |         6          |      192      |
    |         7          |      252      |
    |         8          |      324      |
    |         9          |      432      |
    |         10         |      540      |
    |         11         |      720      |
    |         12         |      960      |
    |         13         |     1200      |
    |         14         |     1440      |

    : Figure 11.1 WTP survey categories (original value) and euro amounts (new value).

## **R WALK-THROUGH 11.1**

### Importing data and recoding variables

Before importing data in Excel or .csv format, open it in a spreadsheet program (such as Excel) to ensure you understand the structure of the data and check if any additional options are required for the `read_excel` function in order to import the data correctly. In this case, the data is in a worksheet called 'Data', there are no missing values to worry about, and the first row contains the variable names. This format is straightforward to import. We can therefore import the data using the `read_excel` function without any additional options.

```{r}
library(tidyverse)
library(readxl)
library(knitr)

# Set your working directory to the correct folder.
# Insert your file path for 'YOURFILEPATH'.
#Importing data and recoding variables
WTP=doing_economics_datafile_working_in_excel_project_11 <- read_excel("~/Mphil/2nd Sem/R-std/doing-economics-datafile-working-in-excel-project-11.xlsx", 
    sheet = "Data")

```

#### Reverse-code variables

The first task is to recode variables related to the respondents' views on certain aspects of government behaviour and attitudes about global warming (`cog_2`, `cog_5`, `scepticism_6`, and `scepticism_7`). This coding makes the interpretation of high and low values consistent across all questions, since the survey questions do not have this consistency.

To recode all of these variables in one go, we use the piping operator (**`%>%`**), which can perform the same sequence of commands on a number of variables at once. (For a more detailed introduction to piping, see the [University of Manchester's Econometric Computing Learning Resource](https://tinyco.re/5531433).) Note that even though the value of 3 for these variables will stay the same, for the `recode` function to work properly we have to specify how each new value corresponds to a previous value.

```{r}
WTP <- WTP %>%
  mutate_at(c("cog_2", "cog_5", 
    "scepticism_6", "scepticism_7"),
    funs(recode(., "1" = 5, "2" = 4, "3" = 3, 
      "4" = 2, "5" = 1)))
```

#### Create new variables containing WTP amounts

Although we could employ the same technique as above to recode the value for the minimum and maximum willingness to pay variables, an alternative is to use the `merge` function. This function allows us to combine two dataframes via values given in a particular variable.

We start by creating a new dataframe (`category_amount`) that has two variables: the original category value and the corresponding new euro amount. We then apply the `merge` function to the WTP dataframe and the new dataframe, specifying the variables that link the data in each dataframe together (`by.x` indicates which variable in the first dataframe, here `WTP`, is to be matched to `by.y`, the variable in the second dataframe, here `category_amount`). We also use the `all.x = TRUE` option to keep all observations, otherwise the `merge` function will drop any observations with missing values for the `WTP_plmin` and `WTP_plmax` variables. Finally we have to rename the column of the merged new values to something more meaningful (`WTP_plmin_euro` and `WTP_plmax_euro` respectively).

```{r}
# Vector containing the Euro amounts
wtp_euro_levels <- c(48, 72, 84, 108, 156, 192, 252, 324, 
                     432, 540, 720, 960, 1200, 1440)

# Create mapping dataframe
category_amount <- data.frame(original = 1:14, 
                              new = wtp_euro_levels)

# Merge and rename for the minimum WTP
WTP <- merge(WTP, category_amount, 
             by.x = "WTP_plmin", by.y = "original", 
             all.x = TRUE)

# Rename the column for the minimum WTP
names(WTP)[names(WTP) == "new"] <- "WTP_plmin_euro"

# Merge and rename for the maximum WTP
WTP <- merge(WTP, category_amount, 
             by.x = "WTP_plmax", by.y = "original", 
             all.x = TRUE)

# Rename the column for the maximum WTP
names(WTP)[names(WTP) == "new"] <- "WTP_plmax_euro"

```

3.  Create the following indices, giving them an appropriate name in your spreadsheet (make sure to use the reverse-coded variable wherever relevant):

    \(a\) Belief that climate change is a real phenomenon: Take the mean of `scepticism_2`, `scepticism_6`, and `scepticism_7`.

    \(b\) Preferences for government intervention to solve problems in society: Take the mean of `cog_1`, `cog_2`, `cog_3`, `cog_4`, `cog_5`, and `cog_6`.

    \(c\) Feeling of personal responsibility to act pro-environmentally: Take the mean of `PN_1`, `PN_2`, `PN_3`, `PN_4`, `PN_6`, and `PN_7`.

## **R WALK-THROUGH 11.2**

### Creating indices

We can create all of the required indices in three steps using the `rowMeans` function. In each step we use the `cbind` function to join the required variables (columns) together as a matrix. As the data is stored as a single observation per row, the index value is the average of the values in each row of this matrix, which we calculate using the `rowMeans` function.

```{r}
WTP <- WTP %>%
  # Ensure subsequent operations are applied by row
  rowwise() %>%
  mutate(., climate = rowMeans(cbind(
    scepticism_2, scepticism_6, scepticism_7))) %>%
  mutate(., gov_intervention = rowMeans(cbind(
    cog_1, cog_2, cog_3, cog_4, cog_5, cog_6))) %>%
  mutate(., pro_environment  = rowMeans(cbind(
    PN_1, PN_2, PN_3, PN_4, PN_6, PN_7))) %>%
  # Return the dataframe to the original format
  ungroup()
```

When creating indices, we may be interested to see if each item used in the index measures the same underlying concept of interest (known as reliability or consistency). There are two common ways to assess reliability: either look at the correlation between items in the index, or use a summary measure called **Cronbach's alpha**⁠ (this measure is used in the social sciences). We will be calculating and interpreting both of these measures.

Cronbach's alpha is a way to summarize the correlations between many variables, and ranges from 0 to 1, with 0 meaning that all of the items are independent of one another, and 1 meaning that all of the items are perfectly correlated with each other. While higher values of this measure indicate that the items are closely related and therefore measure the same concept, with values that are very close to 1 (or 1), we could be concerned that our index contains redundant items (for example, two items that tell us the same information, so we would only want to use one or the other, but not both). You can read more about this in the paper ['Using and interpreting Cronbach's Alpha'](https://tinyco.re/1644975).

4.  Calculate correlation coefficients and interpret Cronbach's alpha:

\(a\) For one of the indices you created in Question 3, create a correlation table to show the correlation between each of the items in the index. Remember to give the variables meaningful names in your table (refer to the 'Data dictionary' tab for descriptions of each variable). Figure 11.2 shows an example for Question 3*(a)*. (Remember that the correlation between A and B is the same as the correlation between B and A, so you only need to calculate the correlation for each pair of items once). Are the items in that index strongly correlated?

|                        | **exaggeration** | **not.human.activity** | no.evidence |
|:----------------------:|:----------------:|:----------------------:|:-----------:|
|    **exaggeration**    |        1         |           \-           |     \-      |
| **not.human.activity** |                  |           1            |     \-      |
|    **no.evidence**     |                  |                        |      1      |

: Figure 11.2 Correlation table for survey items on climate change scepticism: Climate change is exaggerated (exaggeration), Human activity is not the main cause of climate change (not.human.activity), No evidence of global warming (no.evidence).

\(b\) Use the `alpha` function (part of the `psych` package included with R) to compute the Cronbach's alpha for these indices. Interpret these values in terms of index reliability.

## **R WALK-THROUGH 11.3**

### Calculating correlation coefficients

#### Calculate correlation coefficients and Cronbach's alpha

We covered calculating correlation coefficients in [R walk-through 10.1](https://www.core-econ.org/doing-economics/book/text/10-03.html#r-walk-through-101-importing-an-excel-spreadsheet-into-r). In this case, since there are no missing values we can use the `cor` function without any additional options.

For the questions on climate change:

```{r}
cor(cbind(WTP$scepticism_2, WTP$scepticism_6, 
  WTP$scepticism_7))
```

For the questions on government behaviour:

```{r}
cor(cbind(WTP$cog_1, WTP$cog_2, WTP$cog_3, 
  WTP$cog_4, WTP$cog_5, WTP$cog_6))
```

For the questions on personal behaviour:

```{r}
cor(cbind(WTP$PN_1, WTP$PN_2, WTP$PN_3, 
  WTP$PN_4, WTP$PN_6, WTP$PN_7))
```

#### Calculate Cronbach's alpha

It is straightforward to compute the Cronbach's alpha using the `alpha` function from the `psych` package. This function calculates Cronbach's alpha and stores it in **`$`**`total$std.alpha`.

```{r}
psych::alpha(WTP[c("scepticism_2", 
  "scepticism_6", "scepticism_7")])$total$std.alpha
```

```{r}
psych::alpha(WTP[c("cog_1", "cog_2", "cog_3", 
  "cog_4", "cog_5", "cog_6")])$total$std.alpha
```

```{r}
psych::alpha(WTP[c("PN_1", "PN_2", "PN_3", 
  "PN_4", "PN_6", "PN_7")])$total$std.alpha
```

Now we will compare characteristics of people in the dichotomous choice (DC) group and two-way payment ladder (TWPL) group (the variable `abst_format` indicates which group an individual belongs to). Since the groups are of different sizes, we will use percentages instead of frequencies.

5.  For each group (DC and TWPL), create tables to summarize the distribution of the following variables (a separate table for each variable):

-   gender (`sex`)

-   age (`age`)

-   number of children (`kids_nr`)

-   household net income per month in euros (`hhnetinc`)

-   membership in environmental organization (`member`)

-   highest educational attainment (`education`).

Using the tables you have created, and without doing formal calculations, discuss any similarities/differences in demographic characteristics between the two groups.

## **R WALK-THROUGH 11.4**

### Using loops to obtain summary statistics

The two different formats (DC and TWPL) are recorded in the variable `abst_format`, and take the values `ref` and `ladder` respectively. We will store all the variables of interest into a list called `variables`, and use a 'for' loop to calculate summary statistics for each variable and present it in a table.

```{r}
variables <- list(quo(sex), quo(age),
  quo(kids_nr), quo(hhnetinc),
  quo(member), quo(education))

for (i in seq_along(variables)){
  WTP %>%
    group_by(abst_format, !!variables[[i]]) %>%
    summarize (n = n()) %>%
    mutate(freq = n / sum(n)) %>%
    select(-n) %>%
    spread(abst_format, freq) %>%
    print()
}
```

The output above gives the required tables, but is not easy to read. You may want to tidy up the results, for example by translating (from German to English) and reordering the options in the household net income variable (`hhnetinc`).

6.  Create a separate summary table as shown in Figure 11.3 for each of the three indices you created in Question 3. Without doing formal calculations, do the two groups of individuals look similar in the attitudes specified?

    |                 | **Mean** | **Standard deviation** | **Min** | **Max** |
    |:---------------:|:--------:|:----------------------:|:-------:|:-------:|
    |  **DC format**  |          |                        |         |         |
    | **TWPL format** |          |                        |         |         |

    : Figure 11.3 Summary table for indices.

## **R WALK-THROUGH 11.5**

### Calculating summary statistics

The `summarize_at` function can provide multiple statistics for a number of variables in one command. Simply provide a list of the variables you want to summarize and then use the `funs()` option to specify the summary statistics you need. Here, we need the `mean`, `sd`, `mean`, and `max` for the variables `climate`, `gov_intervention`, and `pro_environment`.

```{r}
WTP %>%
  group_by(abst_format) %>%
  summarise_at(c("climate", "gov_intervention", 
      "pro_environment"),
    funs(mean, sd, min, max)) %>%
  # Use gather and spread functions to reformat output 
  # for aesthetic reasons
  gather(index, value, 
    climate_mean:pro_environment_max) %>%
  spread(abst_format, value) %>%
  kable(., format = "markdown", digits = 2) 
```

## [**Part 11.2 Comparing willingness to pay across methods and individual characteristics**](https://www.core-econ.org/doing-economics/book/text/11-03.html#part-112-comparing-willingness-to-pay-across-methods-and-individual-characteristics)

> ### **Learning objectives for this part**
>
> -   compare survey measures of willingness to pay.

Before comparing WTP across question formats, we will summarize the distribution of WTP within each question format.

1.  For individuals who answered the TWPL question:

-   Use the variables `WTP_plmin` and `WTP_plmax` to create column charts (one for each variable) with frequency on the vertical axis and category (the numbers 1--14) on the horizontal axis. Describe characteristics of the distributions shown on the charts.

<!-- -->

-   Using the variables you created in Question 2*(b)* in Part 11.1 (showing the actual WTP amounts), make a new variable that contains the average of the two variables (i.e. for each individual, calculate the average of the minimum and maximum willingness to pay).

<!-- -->

-   Calculate the mean and median of the variable you created in Question 1*(b)*.

<!-- -->

-   Using the variable from Question 1*(b)*, calculate the correlation between individuals' average WTP and the demographic and attitudinal variables (see Questions 3 and 5 from Part 11.1 for a list of these variables). Interpret the relationships implied by the coefficients.

## **R WALK-THROUGH 11.6**

### Summarizing willingness to pay variables

#### Create column charts for minimum and maximum WTP

Before we can plot a column chart, we need to compute frequencies (number of observations) for each value of the willingness to pay (1--14). We do this separately for the minimum and maximum willingness to pay.

In each case we select the relevant variable and remove any observations with missing values using the `na.omit` function. We can then separate the data by level (WTP amount) of the `WTP_plmin_euro` or `WTP_PLmax_euro` variables (using `group_by`), then obtain a frequency count using the `summarize` function. We also use the `factor` function to set this variable's type to factor, to get the correct horizontal axis labels in the column chart.

Once we have the frequency count stored as a dataframe, we can plot the column charts.

For the minimum willingness to pay:

```{r}
df.plmin <- WTP %>%
  select(WTP_plmin_euro) %>%
  na.omit() %>%
  group_by(WTP_plmin_euro) %>%
  summarize(n = n()) %>%
  mutate(WTP_plmin_euro = factor(WTP_plmin_euro, 
    levels = wtp_euro_levels))

ggplot(df.plmin, aes(x=reorder(WTP_plmin_euro,-n), n)) +
  geom_bar(stat = "identity",color = "skyblue", fill="skyblue", position = "identity") + 
  xlab("Minimum WTP (euros)") + 
  ylab("Frequency") +
  theme_bw()
```

**Figure 11.4** Minimum WTP (euros).

For the maximum willingness to pay:

```{r}
df.plmax <- WTP %>%
  select(WTP_plmax_euro) %>%
  na.omit() %>%
  group_by(WTP_plmax_euro) %>%
  summarize(n = n()) %>%
  mutate(WTP_plmax_euro = factor(WTP_plmax_euro, 
    levels = wtp_euro_levels))

ggplot(df.plmax, aes(x=reorder(WTP_plmax_euro,-n), n)) +
  geom_bar(stat = "identity",color = "skyblue", fill="skyblue", position = "identity") + 
  xlab("Maximum WTP (euros)") + 
  ylab("Frequency") +
  theme_bw()
```

**Figure 11.5** Maximum WTP (euros).

#### Calculate average WTP for each individual

We can use the `rowMeans` function to obtain the average of the minimum and maximum willingness to pay.

```{r}
WTP <- WTP %>%
  rowwise() %>%
  mutate(., WTP_average = rowMeans(cbind(
    WTP_plmin_euro, WTP_plmax_euro))) %>%
  ungroup()
```

#### Calculate mean and median WTP across individuals

The mean and median of this average value can be obtained using the `mean` and `median` functions, although we have to use the `na.rm = TRUE` option to handle missing values correctly.

```{r}
mean(WTP$WTP_average, na.rm = TRUE)
```

```{r}
median(WTP$WTP_average, na.rm = TRUE)
```

#### Calculate correlation coefficients

We showed how to obtain a matrix of correlation coefficients for a number of variables in [R walk-through 8.8](https://www.core-econ.org/doing-economics/book/text/08-03.html#r-walk-through-88-creating-dummy-variables-and-calculating-correlation-coefficients). We use the same process here, storing the coefficients in an object called `M`.

```{r}

WTP %>%
  mutate(gender = as.numeric(ifelse(sex == "female", 0, 1))) %>%
  select(WTP_average, education, gender, climate, gov_intervention, pro_environment) %>%
  cor(use = "pairwise.complete.obs") -> M

# Extract the correlation matrix
 M[, "WTP_average"]


```

2.  For individuals who answered the DC question:

-   Each individual was given an amount and had to decide 'yes', 'no', or 'no vote/abstain from deciding'. Make a table showing the frequency of `DC_ref_outcome`, with `costs` as the row variable and `DC_ref_outcome` as the column variable.

<!-- -->

-   Use this table to calculate the percentage of individuals who voted 'no' and 'yes' for each amount (in other words as a percentage of the row total, not the overall total). Count individuals who chose 'abstain' as voting 'no'.

<!-- -->

-   Make a line chart showing the 'demand curve', with percentage of individuals who voted 'yes' as the vertical axis variable and amount (in euros) as the horizontal axis variable. Describe features of this 'demand curve' that you find interesting.

<!-- -->

-   Repeat Question 2*(b)*, this time excluding individuals who chose 'abstain' from the calculations. Plot this new 'demand curve' on the chart created for Question 2*(c)*. Do your results change qualitatively depending on how you count individuals who did not vote?

## **R WALK-THROUGH 11.7**

### Summarizing Dichotomous Choice (DC) variables

#### Create frequency table for DC_ref_outcome

We can group by `costs` and `DC_ref_outcome` to obtain the number of observations for each combination of amount and vote response. We can also `recode` the voting options to 'Yes', 'No', and 'Abstain'.

```{r}
WTP_DC <- WTP %>%
  group_by(costs, DC_ref_outcome) %>%
  summarize(n = n()) %>%
  na.omit() %>%
  mutate_at("DC_ref_outcome", 
    funs(recode(., 
      "do not support referendum and no pay" = "No",
      "support referendum and pay" = "Yes",
      "would not vote" = "Abstain"))) %>%
  spread(DC_ref_outcome, n)

kable(WTP_DC, format = "markdown", digits = 2)

```

#### Add column showing proportion voting yes or no

We can extend the table from Question 2*(a)* to include the proportion voting yes or no (to obtain percentages, multiply the values by 100).

```{r}
WTP_DC <- WTP_DC %>%
  mutate(total = Abstain + No + Yes, 
    prop_no = (Abstain + No) / total, 
    prop_yes = Yes / total) %>%
  # Round all numbers to 2 decimal places
  mutate_if(is.numeric, funs(round(., 2)))

kable(WTP_DC, format = "markdown", digits = 2)
```

#### Make a line chart of WTP

Using the dataframe generated for Questions 2*(a)* and *(b)* (`WTP_DC`), we can plot the 'demand curve' as a scatterplot with connected points by using the `geom_point` and `geom_line` options for `ggplot`. Adding the extra option `scale_x_continuous` changes the default labeling on the horizontal axis to display ticks at every 100 euros, enabling us to read the chart more easily.

```{r}
p <- ggplot(WTP_DC, aes(y = prop_yes, x = costs)) +
  geom_point() + 
  geom_line(size = 1) +
  ylab("% Voting 'Yes'") + 
  xlab("Amount (euros)") +
  scale_x_continuous(breaks = seq(0, 1500, 100)) +
  theme_bw()

print(p)

```

**Figure 11.6** Demand curve (in euros), DC method.

#### Calculate new proportions and add them to the table and chart

It is straightforward to calculate the new proportions and add them to the existing dataframe, however, we will need to reshape the data (using `gather`) to plot multiple lines on the same scatterplot.

```{r}
WTP_DC <- WTP_DC %>%
  mutate(total_ex = No + Yes, 
    prop_no_ex = No / total_ex, 
    prop_yes_ex = Yes / total_ex) %>%
  # Round all numbers to 2 decimal places
  mutate_if(is.numeric, funs(round(., 2)))

kable(WTP_DC, format = "markdown", digits = 2)

```

```{r}
WTP_DC %>%
  select(costs, prop_yes, prop_yes_ex) %>%
  gather(Vote, value, prop_yes:prop_yes_ex) %>%
  ggplot(., aes(y = value, x = costs, color = Vote)) + 
    geom_line(size = 1) + 
    geom_point() +
    ggtitle("'Demand curve' from DC respondents, under 
      different treatments for 'Abstain' responses.") +
    scale_color_manual(values = c("blue", "red"), 
      labels = c("counted as no", "excluded")) +
    ylab("% voting 'yes'") + 
    xlab("Costs (euros)") +
    theme_bw()
```

**Figure 11.7** Demand curve from DC respondents, under different treatments for 'Abstain' responses.

3.  Compare the mean and median WTP under both question formats:

-   Complete Figure 11.8 and use it to calculate the difference in means (DC minus TWPL), the standard deviation of these differences, and the number of observations. (The mean of DC is the mean of `DC_ref_outcome` for individuals who voted `yes`.)

-   Obtain 95% confidence intervals for the difference of means for each question format. Discuss your findings.

<!-- -->

-   Does the median WTP look different across question formats? (You do not need to do any formal calculations.)

<!-- -->

-   Using your answers to Questions 3*(a)*--*(c)*, would you recommend that governments use the mean or median WTP in policy making decisions? (That is, which measure appears to be more robust to changes in the question format?)

## **R WALK-THROUGH 11.8**

### Calculating confidence intervals for differences in means

#### Calculate the difference in means, standard deviations, and number of observations

We first create two vectors that will contain the WTP values for each of the two question methods. For the DC format, willingness to pay is recorded in the `costs` variable, so we select all observations where the `DC_ref_outcome` variable indicates the individual voted 'yes' and drop any missing observations. For the TWPL format we use the `WTP_average` variable that we created in [R walk-through 11.6](https://www.core-econ.org/doing-economics/book/text/11-03.html#r-walk-through-116-summarizing-willingness-to-pay-variables).

```{r}
DC_WTP <- WTP %>% subset(
  DC_ref_outcome == "support referendum and pay") %>%
  select(costs) %>%
  filter(!is.na(costs)) %>%
  as.matrix()

# Print out the mean, sd, and count
cat(sprintf("DC Format - mean: %.1f, 
  standard deviation %.1f, count %d\n",
  mean(DC_WTP), sd(DC_WTP), length((DC_WTP))))
```

```{r}
TWPL_WTP <- WTP %>%
  select(WTP_average) %>%
  filter(!is.na(WTP_average)) %>%
  as.matrix()

cat(sprintf("TWPL Format - mean: %.1f, 
  standard deviation %.1f, count %d\n", 
  mean(TWPL_WTP), sd(TWPL_WTP),
  length((TWPL_WTP))))
```

#### Calculate 95% confidence intervals

Using the `t.test` function to obtain 95% confidence intervals was covered in [R walk-throughs 8.10](https://www.core-econ.org/doing-economics/book/text/08-03.html#r-walk-through-810-calculating-confidence-intervals-and-adding-error-bars) and [10.6](https://www.core-econ.org/doing-economics/book/text/10-03.html#r-walk-through-106-calculating-confidence-intervals). As we have already separated the data for the two different question formats in Question 3(*a*), we can obtain the confidence interval directly.

```{r}
t.test(DC_WTP, TWPL_WTP, conf.level = 0.05)$conf.int
```

#### Calculate median WTP for the DC format

In [R walk-through 11.6](https://www.core-econ.org/doing-economics/book/text/11-03.html#r-walk-through-116-summarizing-willingness-to-pay-variables) we obtained the median WTP for the TWPL format (132). We now obtain the WTP using the DC format.

```{r}
median(DC_WTP)
```

-   [Leading think tanks](https://tinyco.re/8311899) estimate that the world needs 20 trillion USD of investment in low-carbon energy supplies and energy efficient technologies by 2030 to meet the Paris Agreement targets. This amount roughly corresponds to 3,273 euros total per adult (aged 15 and above), or 298 euros per adult per year (2020 to 2030 inclusive).

    Compare this approximate number with the WTP estimates you have found. Assuming people around the world have the same attitudes towards climate change as the Germans surveyed, would a tax equal to the median WTP be enough to finance climate change mitigation? Discuss how governments could increase public support for and involvement in climate change mitigation activities.
